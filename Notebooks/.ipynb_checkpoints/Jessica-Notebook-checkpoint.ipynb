{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a81f08-7e47-4581-a3f3-9de5d1282739",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Avocado Production\n",
    "\n",
    "- [Avocado Production Worldwide](https://ourworldindata.org/grapher/avocado-production)\n",
    "- [California Avocado Production 1980-2020](https://www.kaggle.com/datasets/jarredpriester/california-avocado-production-19802020)\n",
    "- [3 datasets on Dataworld](https://data.world/datasets/avocados)\n",
    "- [GitHub Topic on Avocado](https://github.com/topics/avocado-dataset)\n",
    "- [Statista Avocado production worldwide](https://www.statista.com/statistics/577455/world-avocado-production/)\n",
    "-[Hass Avocados R Package](https://cran.r-project.org/web/packages/avocado/vignettes/a_intro.html)\n",
    "- [Avocado Source](https://www.avocadosource.com/)\n",
    "- [Hass Avocado Board](https://hassavocadoboard.com/)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a674e7-d084-49ba-bb7a-b12e34aed2f4",
   "metadata": {},
   "source": [
    "### Table of Contents <a class=\"anchor\" id=\"AVO_toc\"></a>\n",
    "\n",
    "* [Table of Contents](#AVO_toc)\n",
    "    * [Page 1 - Abstract](#AVO_page_1)\n",
    "    * [Page 2 - Imported Libraries](#AVO_page_2)\n",
    "    * [Page 3 - Import the Dataset](#AVO_page_3)\n",
    "    * [Page 4 - Setting Notebook Options](#AVO_page_4)\n",
    "    * [Page 5 - Looking at the Data](#AVO_page_5)\n",
    "    * [Page 6 - Get Descriptive Statistics about the Dataset](#AVO_page_6)\n",
    "    * [Page 7 - Filter for Three Cities](#AVO_page_7)\n",
    "    * [Page 8 - Recoding](#AVO_page_8)\n",
    "    * [Page 9 - Test for Assumptions](#AVO_page_9)\n",
    "    * [Page 10 - Correlation analysis](#AVO_page_10)\n",
    "    * [Page 11 - Regression analysis](#AVO_page_11)\n",
    "    * [Page 12 - T-tests](#AVO_page_12)\n",
    "    * [Page 13 - Chi-squared test](#AVO_page_13)\n",
    "    * [Page 14 - Time-series analysis](#AVO_page_14)\n",
    "    * [Page 15 - Summary](#AVO_page_15)\n",
    "    * [Page 16 - Future Work](#AVO_page_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b2c19-3dd7-4fa5-9a1c-afc0e520b1bb",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 1 - Abstract <a class=\"anchor\" id=\"AVO_page_1\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22623520-6bd9-42ca-b812-c33c4383eb3f",
   "metadata": {},
   "source": [
    "Research on Avocado Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053fd1d-5aa4-423b-9eae-72552c64cf7a",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 2 - Imported Libraries<a class=\"anchor\" id=\"AVO_page_2\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911b52a-f496-472a-8619-19870c55476d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import bartlett, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4645a-71c5-433e-8637-a9d1ce12a88f",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 3 - Import the Dataset <a class=\"anchor\" id=\"AVO_page_3\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c280e-5c95-4d2b-9cef-0f0205d022f7",
   "metadata": {},
   "source": [
    "## Research, find datasets and read in your data\n",
    "We found three datasets to work on, we'll work on the first:\n",
    "\n",
    "- [USA 2015-2018](../Data/avocados-us-2015-1018.csv)\n",
    "\n",
    "This dataset contains information about avocado sales in various regions from 2015 to 2018. Here are some interesting descriptive statistics that can be derived from this dataset:\n",
    "\n",
    "1. The average price of avocados across all regions and years.\n",
    "2. The total volume of avocados sold across all regions and years.\n",
    "3. The total volume of each type of avocado sold (4046, 4225, 4770) across all regions and years.\n",
    "4. The average price of avocados in each region and for each year.\n",
    "5. The total number of bags sold across all regions and years, and the proportion of each type of bag (small, large, XL) sold.\n",
    "6. The number of avocados sold in each region and for each year.\n",
    "7. The distribution of avocado prices for each region and for each year.\n",
    "\n",
    "here are the other two:\n",
    "- [Worldwide 1961-2020](../Data/avocado-production-worldwide-1961-2021.csv)\n",
    "- [California 1980-2020](../Data/avocados-california-1980-2020.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75904fc7-3d4a-475f-9ab7-07326c468c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### start code\n",
    "df = pd.read_csv('../Data/avocados-us-2015-1018.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df.head()\n",
    "### end code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7044f-5b69-494d-bc7d-089a77d150fb",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 4 - Setting Notebook Options<a class=\"anchor\" id=\"AVO_page_4\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5380f-ca58-4d64-be71-2b84e1149297",
   "metadata": {},
   "source": [
    "#### Check number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa07388-4f3c-46ff-bf4a-146e77a32881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Rows: {df.shape[0]}')\n",
    "print(f'Columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bb48b-e011-4aab-a7ae-99a23a2541c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reset the options\n",
    "#pd.reset_option('display.max_rows')\n",
    "\n",
    "# set the option to display the maximum number of columns\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "# set the option to display the minimum and maximum number of rows\n",
    "pd.set_option('display.min_rows', 200)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "pd.describe_option('display.max_rows')\n",
    "pd.describe_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d844df-6911-44f7-80c4-3b548ecb8363",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 5 - EDA: Looking at the Data<a class=\"anchor\" id=\"AVO_page_5\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97480ad-b620-40ec-b67a-864f667445f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the column names \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cbaab9-59c0-4aa6-b12c-686033f6890f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print unique values for type column\n",
    "df.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00764802-24e4-4b34-bef5-f59e7ba53086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print unique values for region column\n",
    "df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecbda3-8103-495f-8a1a-e141f0dab0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb919a-db7c-48c0-8c57-869068329d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AveragePrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3a557-9ca5-45f9-bd1b-f05488630cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# usually objects are you key factors/independent variables where floats and ints are continuous/dependent variables\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e92b1-82fa-464a-8d50-3a93fc6ce05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# notice that the Date column is an object and not a proper date object let's create a new column as a date object\n",
    "# convert string column to date column\n",
    "#df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fe1cf-b3db-4a37-8933-d7841ba9054a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is a large dataset and will be truncated to 11 rows unless you set your row and column options\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53346c06-fffb-41e8-bc52-21951aea1fa4",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 6 - Get Descriptive Statistics about the Dataset<a class=\"anchor\" id=\"AVO_page_6\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579445b-8cc2-4e15-a846-b856482e9abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#What is the average price of avocados across all regions and years.\n",
    "\n",
    "# Calculate the mean of the 'AveragePrice' column\n",
    "average_price = df[\"AveragePrice\"].mean()\n",
    "\n",
    "print(\"The average price of avocados across all regions and years is:\", average_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee125b0-cf62-4963-ae81-ccccb62ab361",
   "metadata": {},
   "source": [
    "In this code, we first import the pandas library and read the avocado dataset into a pandas DataFrame. We then use the mean() method to calculate the average of the 'AveragePrice' column, which gives us the average price of avocados across all regions and years. Finally, we print out the result using the print() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc57b8-321b-4aed-b93f-a075a7108ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'year' and 'region' and calculate the mean of the 'AveragePrice' column for each group\n",
    "avg_price_by_region_year = df.groupby(['year', 'region'])['AveragePrice'].mean()\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "avg_price_by_region_year = avg_price_by_region_year.reset_index()\n",
    "\n",
    "# Set the size of the figure using matplotlib\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the average price of avocados across all regions and years\n",
    "sns.lineplot(data=avg_price_by_region_year, x='year', y='AveragePrice')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Average Price of Avocados Across All Regions and Years')\n",
    "\n",
    "# Set the labels of the x- and y-axes\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Price (in dollars)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af3772-f11f-4da9-a47d-828c2700948f",
   "metadata": {},
   "source": [
    "In this code, we use the pd.read_csv() function to load the avocado dataset into a pandas DataFrame. We then use the groupby() method to group the DataFrame by 'year' and 'region' and calculate the mean of the 'AveragePrice' column for each group. We store this object in the variable avg_price_by_region_year.\n",
    "\n",
    "Next, we use the reset_index() method to reset the index of the resulting DataFrame to integers. This is necessary to plot the DataFrame with seaborn.\n",
    "\n",
    "We then use the plt.figure(figsize=(12, 6)) statement to set the size of the figure using matplotlib.\n",
    "\n",
    "We then call the seaborn.lineplot() function to create a line plot of the average price of avocados across all regions and years, with the x parameter set to 'year' and the y parameter set to 'AveragePrice'.\n",
    "\n",
    "Finally, we set the title of the plot using plt.title(), set the labels of the x- and y-axes using plt.xlabel() and plt.ylabel(), and show the plot using plt.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6550db6-69cc-4a0c-8f4c-ce84c52ed1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the total volume of avocados sold across all regions and years.\n",
    "\n",
    "# Calculate the sum of the 'Total Volume' column\n",
    "total_volume = df[\"Total Volume\"].sum()\n",
    "\n",
    "print(\"The total volume of avocados sold across all regions and years is:\", total_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92c6ec-d3df-40a8-89b7-4c855e26a1fd",
   "metadata": {},
   "source": [
    "In this code, we first import the pandas library and read the avocado dataset into a pandas DataFrame. We then use the sum() method to calculate the sum of the 'Total Volume' column, which gives us the total volume of avocados sold across all regions and years. Finally, we print out the result using the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90074e9-cad1-4a24-ad2c-d5209f733565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the total volume of each type of avocado sold (4046, 4225, 4770) across all regions and years.\n",
    "# Calculate the sum of the '4046', '4225', and '4770' columns\n",
    "total_4046 = df[\"4046\"].sum()\n",
    "total_4225 = df[\"4225\"].sum()\n",
    "total_4770 = df[\"4770\"].sum()\n",
    "\n",
    "print(\"The total volume of 4046 avocados sold is:\", total_4046)\n",
    "print(\"The total volume of 4225 avocados sold is:\", total_4225)\n",
    "print(\"The total volume of 4770 avocados sold is:\", total_4770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836718ad-5a32-49b6-bea1-d195904be0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'year' and sum the values of the '4046', '4225', and '4770' columns for each group\n",
    "total_volume_by_type_year = df.groupby('year')[['4046', '4225', '4770']].sum()\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "total_volume_by_type_year = total_volume_by_type_year.reset_index()\n",
    "\n",
    "# Set the size of the figure using matplotlib\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the total volume of each type of avocado sold for each year\n",
    "plt.plot(total_volume_by_type_year['year'], total_volume_by_type_year['4046'], label='4046')\n",
    "plt.plot(total_volume_by_type_year['year'], total_volume_by_type_year['4225'], label='4225')\n",
    "plt.plot(total_volume_by_type_year['year'], total_volume_by_type_year['4770'], label='4770')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Total Volume of Each Type of Avocado Sold Across All Regions and Years')\n",
    "\n",
    "# Set the labels of the x- and y-axes\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Volume (in millions of units)')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99469f95-1099-485f-bf8f-247d5efe011b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The average price of avocados in each region and for each year.\n",
    "# Calculate the mean of the 'AveragePrice' column grouped by 'region' and 'year'\n",
    "avg_price_by_region_year = df.groupby(['region', 'year'])['AveragePrice'].mean()\n",
    "\n",
    "print(\"The average price of avocados in each region and for each year is:\\n\", avg_price_by_region_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292a76d-02e4-44d1-911d-e2c6fa8c074d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "avg_price_by_region_year = avg_price_by_region_year.reset_index()\n",
    "\n",
    "# Set the size of the figure using matplotlib\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Create a line plot of the average price of avocados for each region and year\n",
    "sns.lineplot(data=avg_price_by_region_year, x='year', y='AveragePrice', hue='region')\n",
    "\n",
    "# Move the legend to the top and make it smaller\n",
    "#plt.legend(loc='upper left', bbox_to_anchor=(0.2, 0.50), ncol=3, fontsize='small')\n",
    "\n",
    "# Put the legend on the right side and make it smaller\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0, prop={'size': 8})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34595407-bcc4-4945-b8eb-6d1b9497c6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The total number of bags sold across all regions and years, and the proportion of each type of bag (small, large, XL) sold.\n",
    "\n",
    "# Calculate the sum of the 'Total Bags', 'Small Bags', 'Large Bags', and 'XLarge Bags' columns\n",
    "total_bags = df[\"Total Bags\"].sum()\n",
    "total_small_bags = df[\"Small Bags\"].sum()\n",
    "total_large_bags = df[\"Large Bags\"].sum()\n",
    "total_xlarge_bags = df[\"XLarge Bags\"].sum()\n",
    "\n",
    "# Calculate the proportion of each type of bag sold\n",
    "prop_small_bags = total_small_bags / total_bags\n",
    "prop_large_bags = total_large_bags / total_bags\n",
    "prop_xlarge_bags = total_xlarge_bags / total_bags\n",
    "\n",
    "print(\"The total number of bags sold across all regions and years is:\", total_bags)\n",
    "print(\"The proportion of small bags sold is:\", prop_small_bags)\n",
    "print(\"The proportion of large bags sold is:\", prop_large_bags)\n",
    "print(\"The proportion of XLarge bags sold is:\", prop_xlarge_bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed80423-9cbd-41bc-9a37-25182ab49176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of avocados sold in each region and for each year.\n",
    "\n",
    "# Group the DataFrame by 'region' and 'year' and sum the 'Total Volume' column\n",
    "avocado_count_by_region_year = df.groupby(['region', 'year'])['Total Volume'].sum()\n",
    "\n",
    "print(\"The number of avocados sold in each region and for each year is:\\n\", avocado_count_by_region_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b53c5b-b77f-425d-b42b-8fbc73192589",
   "metadata": {},
   "source": [
    "In this code, we first import the pandas library and read the avocado dataset into a pandas DataFrame. We then use the groupby() method to group the DataFrame by 'region' and 'year', and then calculate the sum of the 'Total Volume' column for each group using the sum() method. The resulting object is a pandas Series object that contains the number of avocados sold in each region and for each year. Finally, we print out the results using the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81831808-14ed-408f-8abc-5a517a9576a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The distribution of avocado prices for each region and for each year.\n",
    "\n",
    "# Group the DataFrame by 'region' and 'year' and get the 'AveragePrice' column\n",
    "avocado_prices_by_region_year = df.groupby(['region', 'year'])['AveragePrice']\n",
    "\n",
    "# Set the width of the plot using the 'figure()' function from matplotlib\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "# Use the 'histplot()' method in seaborn to plot the distribution of avocado prices for each region and for each year\n",
    "sns.histplot(data=df, x='AveragePrice', hue='region', multiple='stack', kde=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c5d2c-f5bf-4c75-9852-d1a28fe99b7e",
   "metadata": {},
   "source": [
    "In this code, we first import the pandas, seaborn, and matplotlib libraries and read the avocado dataset into a pandas DataFrame. We then use the groupby() method to group the DataFrame by 'region' and 'year', and then extract the 'AveragePrice' column from each group. We store this object in the variable avocado_prices_by_region_year.\n",
    "\n",
    "Next, we use the figure() function from the matplotlib library to create a new figure with a larger width of 12 inches and a height of 6 inches. We pass this value as a tuple to the figsize parameter of the figure() function.\n",
    "\n",
    "Finally, we use the histplot() method in seaborn to plot the distribution of avocado prices for each region and for each year. The histplot() method takes the DataFrame (data=df), the column to plot (x='AveragePrice'), the grouping variable (hue='region'), and the option to stack the histograms (multiple='stack') and add a kernel density estimate (kde=True).\n",
    "\n",
    "Finally, we use the plt.show() function to display the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48d96c-2fd5-42ec-9a2d-71184fd49bae",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 7 - Filter for Three Cities<a class=\"anchor\" id=\"AVO_page_7\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81917317-6feb-4e67-8eac-6053d6a186de",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Filter for 3 cities\n",
    "Focusing on the Three Categories\n",
    "The data has many more categories than three, so you will need to filter the dataset by the categories you want. The code below makes a list of the categories you want to keep, then searches through the Category column using the isin() function to keep only those that match.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbaef1-17ed-4fb9-93fb-4820fa043c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for New York, Los Angeles, and Chicago\n",
    "cities = ['NewYork', 'LosAngeles', 'Chicago']\n",
    "\n",
    "# you can select a column using dot \".\" notation and use a function called \"isin\"\n",
    "df_filtered = df[df['region'].isin(cities)]\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ea470-06c4-4dde-ae03-d25b92d60117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the size of the figure using matplotlib\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the average price of avocados for each year and city\n",
    "sns.lineplot(data=df_filtered, x='year', y='AveragePrice', hue='region')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Average Price of Avocados in New York, Los Angeles, and Chicago')\n",
    "\n",
    "# Set the labels of the x- and y-axes\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Price (in dollars)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5a0ab-4496-4ac0-8449-8876afce1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.region.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07813508-aa22-4e21-92c2-e78fef73a03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6132ce02-d687-403d-a74c-5d4aa2e999d3",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 8 - Recoding<a class=\"anchor\" id=\"AVO_page_8\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924da75-5d7a-4a5b-8d33-e9791b0bc7e3",
   "metadata": {},
   "source": [
    "#### recode 'type' and 'region' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8eac-4b61-423b-a695-0467b3725bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the dataset\n",
    "df_recoded = df.copy()\n",
    "\n",
    "# Recode the 'type' column\n",
    "df_recoded['type'] = df_recoded['type'].replace({'conventional': 0, 'organic': 1})\n",
    "\n",
    "# Recode the 'region' column\n",
    "region_map = {'Albany': 0, 'Atlanta': 1, 'BaltimoreWashington': 2, 'Boise': 3, 'Boston': 4, 'BuffaloRochester': 5, 'California': 6, 'Charlotte': 7, 'Chicago': 8, 'CincinnatiDayton': 9, 'Columbus': 10, 'DallasFtWorth': 11, 'Denver': 12, 'Detroit': 13, 'GrandRapids': 14, 'GreatLakes': 15, 'HarrisburgScranton': 16, 'HartfordSpringfield': 17, 'Houston': 18, 'Indianapolis': 19, 'Jacksonville': 20, 'LasVegas': 21, 'LosAngeles': 22, 'Louisville': 23, 'MiamiFtLauderdale': 24, 'Midsouth': 25, 'Nashville': 26, 'NewOrleansMobile': 27, 'NewYork': 28, 'Northeast': 29, 'NorthernNewEngland': 30, 'Orlando': 31, 'Philadelphia': 32, 'PhoenixTucson': 33, 'Pittsburgh': 34, 'Plains': 35, 'Portland': 36, 'RaleighGreensboro': 37, 'RichmondNorfolk': 38, 'Roanoke': 39, 'Sacramento': 40, 'SanDiego': 41, 'SanFrancisco': 42, 'Seattle': 43, 'SouthCarolina': 44, 'SouthCentral': 45, 'Southeast': 46, 'Spokane': 47, 'StLouis': 48, 'Syracuse': 49, 'Tampa': 50, 'TotalUS': 51, 'West': 52, 'WestTexNewMexico': 53}\n",
    "df_recoded['region'] = df_recoded['region'].replace(region_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b6590-f95c-4819-9e98-f3b455f0c75f",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 9 - Test for Assumptions<a class=\"anchor\" id=\"AVO_page_9\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1086f014-28d4-45b7-89c5-3dd5e641f2af",
   "metadata": {},
   "source": [
    "#### Test for assumptions\n",
    "\n",
    "- Normality\n",
    "- Homogeneity of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f01ee6-fe1d-46d3-b20f-b2abeac89cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "# Test for normality of the 'AveragePrice' column\n",
    "alpha = 0.05\n",
    "stat, p = normaltest(df_recoded['AveragePrice'])\n",
    "\n",
    "# Print the results of the normality test\n",
    "print(f\"Normality test result for 'AveragePrice':\\nStatistic={stat:.4f}, p-value={p:.4f}\")\n",
    "if p < alpha:\n",
    "    print(\"The null hypothesis (data is normally distributed) can be rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis (data is normally distributed) cannot be rejected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ee8e1-2294-447a-94bd-6c9f984907dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Without Transformation\n",
    "sns.displot(df_recoded['Total Volume'], kde=True).set(title='Without Transformation')\n",
    "\n",
    "# With Square Root Transformation\n",
    "sns.displot(np.sqrt(df_recoded['Total Volume']), kde=True).set(title='With Square Root Transformation')\n",
    "\n",
    "# With Log Transformation\n",
    "sns.displot(np.log(df_recoded['Total Volume']), kde=True).set(title='With Log Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d155270-29c1-4b42-9ead-9618e4b06776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform a log transformation on the 'Total Volume' column of the df_recoded DataFrame\n",
    "df_recoded['Total Volume Log'] = np.log(df_recoded['Total Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455038f-2078-43de-8d3b-95b2269fbaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_recoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e51e6d-f0d6-491b-b6c5-1b944bca0bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the log-transformed 'Total Volume' column to the original dataset\n",
    "df['Total Volume Log'] = df_recoded['Total Volume Log']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089362c-8b17-4736-b9a7-a1c2882999f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In this code, we first import the necessary functions from the scipy.stats module: bartlett(), levene(), and shapiro(). We define a significance level alpha of 0.05.\n",
    "\n",
    "\n",
    "from scipy.stats import bartlett, levene, shapiro\n",
    "\n",
    "# Perform Bartlett's test for homogeneity of variances\n",
    "alpha = 0.05\n",
    "stat, p = bartlett(df_recoded['Total Volume'], df_recoded['Total Volume Log'])\n",
    "print(f\"Bartlett's test result:\\nStatistic={stat:.4f}, p-value={p:.4f}\")\n",
    "if p < alpha:\n",
    "    print(\"The null hypothesis (equal variances) can be rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis (equal variances) cannot be rejected.\")\n",
    "\n",
    "# Perform Levene's test for homogeneity of variances\n",
    "stat, p = levene(df_recoded['Total Volume'], df_recoded['Total Volume Log'])\n",
    "print(f\"Levene's test result:\\nStatistic={stat:.4f}, p-value={p:.4f}\")\n",
    "if p < alpha:\n",
    "    print(\"The null hypothesis (equal variances) can be rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis (equal variances) cannot be rejected.\")\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality\n",
    "stat, p = shapiro(df_recoded['Total Volume Log'])\n",
    "print(f\"Shapiro-Wilk test result:\\nStatistic={stat:.4f}, p-value={p:.4f}\")\n",
    "if p < alpha:\n",
    "    print(\"The null hypothesis (data is normally distributed) can be rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis (data is normally distributed) cannot be rejected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c746bb4-fe6a-4cb1-974c-66476f18d6dd",
   "metadata": {},
   "source": [
    "## explaining the results\n",
    "\n",
    "The results of the tests are used to check the assumptions of normality and homogeneity of variance, which are important assumptions underlying many statistical analyses. Here's what we can infer from the results of the tests:\n",
    "\n",
    "Bartlett's test: The null hypothesis for Bartlett's test is that the variances of different groups are equal. If the p-value is less than the chosen significance level (0.05 in this case), we can reject the null hypothesis and conclude that the variances are not equal. In this case, the p-value is greater than the chosen significance level (p > 0.05), so we cannot reject the null hypothesis. Therefore, we can assume that the variances of the Total Volume and Total Volume Log columns of the df_recoded DataFrame are equal.\n",
    "\n",
    "Levene's test: Levene's test is another test for homogeneity of variances, which is more robust than Bartlett's test when the data is not normally distributed. In this case, the p-value is greater than the chosen significance level (p > 0.05), so we cannot reject the null hypothesis. Therefore, we can assume that the variances of the Total Volume and Total Volume Log columns of the df_recoded DataFrame are equal.\n",
    "\n",
    "Shapiro-Wilk test: The null hypothesis for the Shapiro-Wilk test is that the data is normally distributed. If the p-value is less than the chosen significance level (0.05 in this case), we can reject the null hypothesis and conclude that the data is not normally distributed. In this case, the p-value is less than the chosen significance level (p < 0.05), so we can reject the null hypothesis. Therefore, we can assume that the log-transformed Total Volume column of the df_recoded DataFrame is not normally distributed.\n",
    "\n",
    "In summary, the results suggest that the log-transformed Total Volume column of the df_recoded DataFrame does not follow a normal distribution, but the variances of the Total Volume and Total Volume Log columns are equal. This information can be useful for selecting appropriate statistical tests for analyzing the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263102d9-aadc-4f01-97b6-75d4ec27a681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725bcc5-e2db-45dc-943d-fa2fe6d5c963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Select the rows corresponding to the selected cities\n",
    "cities = ['Chicago', 'NewYork', 'LosAngeles']\n",
    "df_cities = df.loc[df['region'].isin(cities)]\n",
    "\n",
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ec61c-e88b-479f-a92c-1d47cf8e5859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform one-way ANOVA\n",
    "alpha = 0.05\n",
    "stat, p = f_oneway(df_cities['Total Volume Log'][df_cities['region'] == 'Chicago'],\n",
    "                   df_cities['Total Volume Log'][df_cities['region'] == 'NewYork'],\n",
    "                   df_cities['Total Volume Log'][df_cities['region'] == 'LosAngeles'])\n",
    "print(f\"One-way ANOVA result:\\nStatistic={stat:.4f}, p-value={p:.4f}\")\n",
    "if p < alpha:\n",
    "    print(\"The null hypothesis (the means of the populations are equal) can be rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis (the means of the populations are equal) cannot be rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dde697-2ec6-4696-b099-9159a4026c13",
   "metadata": {},
   "source": [
    "#explain your results\n",
    "\n",
    "The one-way ANOVA test conducted on the three cities for avocado production is used to determine whether there is a significant difference between the means of the populations of avocado production in each of the three cities. The null hypothesis of this test is that the means of the populations are equal, while the alternative hypothesis is that at least one of the means is different.\n",
    "\n",
    "The ANOVA test produces two key outputs: the test statistic and the p-value. The test statistic is a measure of how much the sample means deviate from the overall mean, while the p-value is the probability of observing such a deviation by chance if the null hypothesis were true.\n",
    "\n",
    "In this case, the one-way ANOVA result shows that the test statistic is 34.1755, and the p-value is 0.0000. Since the p-value is less than the commonly used threshold of 0.05, we can reject the null hypothesis that the means of the populations are equal, and conclude that there is a significant difference between the means of avocado production in at least one of the three cities.\n",
    "\n",
    "In other words, the ANOVA test suggests that there is evidence of a difference in avocado production between the three cities. However, the ANOVA test alone cannot tell us which cities are different from each other. To determine which city or cities are different, we would need to conduct post-hoc tests such as Tukey's HSD or Bonferroni's correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11263e0-d94d-47f9-8250-b44eda61d953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cities['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28faa9-b2d2-44fe-97ab-6d3192c862a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb9f23-06f5-4ec0-9f39-d64286788cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform one-way ANOVA\n",
    "anova = f_oneway(df_cities[df_cities['region'] == cities[0]]['Total Volume'],\n",
    "                 df_cities[df_cities['region'] == cities[1]]['Total Volume'],\n",
    "                 df_cities[df_cities['region'] == cities[2]]['Total Volume'])\n",
    "\n",
    "# Print ANOVA results\n",
    "print(\"One-way ANOVA result:\\n\", anova)\n",
    "\n",
    "# Perform Bartlett's test for homogeneity of variances\n",
    "bartlett_test = bartlett(df_cities[df_cities['region'] == cities[0]]['Total Volume'],\n",
    "                         df_cities[df_cities['region'] == cities[1]]['Total Volume'],\n",
    "                         df_cities[df_cities['region'] == cities[2]]['Total Volume'])\n",
    "\n",
    "# Print Bartlett's test results\n",
    "print(\"\\n\")\n",
    "print(\"Bartlett's test for homogeneity of variances:\\n\", bartlett_test)\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "mc = MultiComparison(df_cities['Total Volume'], df_cities['region'])\n",
    "tukey = mc.tukeyhsd()\n",
    "\n",
    "# Print Tukey's HSD results\n",
    "print(\"\\n\")\n",
    "print(\"Tukey's HSD post-hoc test:\\n\", tukey)\n",
    "\n",
    "# Perform Bonferroni correction post-hoc test\n",
    "p_values = tukey.pvalues\n",
    "adjusted_p_values = p_values * len(p_values)\n",
    "reject = adjusted_p_values < 0.05\n",
    "\n",
    "# Print Bonferroni correction results\n",
    "print(\"Bonferroni correction post-hoc test:\\n\", adjusted_p_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a39617-8d49-4d69-b24b-86525e1caed1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explained results\n",
    "\n",
    "The results show the output of a one-way ANOVA on the Total Volume of avocados sold in three cities: Chicago, Los Angeles, and New York.\n",
    "\n",
    "The F_onewayResult output indicates that there is a significant difference between the means of the three cities (F-statistic = 115.182, p-value = 8.62e-46).\n",
    "\n",
    "Bartlett's test for homogeneity of variances is a test for whether the variances are equal across groups. The BartlettResult output indicates that the variances are significantly different across groups (Bartlett's statistic = 562.733, p-value = 6.37e-123). Therefore, it is not appropriate to use an ANOVA assuming equal variances across groups.\n",
    "\n",
    "Tukey's HSD post-hoc test is a multiple comparison test that compares the means of all pairs of groups. The output shows the mean difference between each pair of groups, the p-value after adjustment for multiple comparisons using the False Discovery Rate, and whether the null hypothesis of equal means can be rejected (reject=True) or not (reject=False). The output indicates that all pairs of groups have significantly different means (p < 0.05), and thus the null hypothesis of equal means can be rejected.\n",
    "\n",
    "The Bonferroni correction post-hoc test is another method for controlling the family-wise error rate (FWER) when performing multiple comparisons. The output shows the adjusted p-values after Bonferroni correction for each pairwise comparison. The output indicates that all pairs of groups have p-values less than 0.05/3 = 0.0167, which is the Bonferroni-corrected significance level. Therefore, all pairwise comparisons are significant at the 0.05 level after Bonferroni correction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897f7e8-090c-4590-be3d-d7aadac3efd4",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 10 - Correlation analysis<a class=\"anchor\" id=\"AVO_page_10\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45ed2c-d853-4b31-9018-b34ca40eb3fe",
   "metadata": {},
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de62d7-45df-47c2-8986-07f767636a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient between Average Price and Total Volume\n",
    "corr_coeff = df['AveragePrice'].corr(df['Total Volume'])\n",
    "\n",
    "print(\"The correlation coefficient between Average Price and Total Volume is:\", corr_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d380b-e9b4-4d19-abb2-0d26f5649c7a",
   "metadata": {},
   "source": [
    "## Explained results\n",
    "\n",
    "The corr() method in pandas calculates the correlation coefficient between two variables. The result will be a value between -1 and 1, where -1 indicates a strong negative correlation, 0 indicates no correlation, and 1 indicates a strong positive correlation.\n",
    "\n",
    "In this case, we are interested in the correlation between Average Price and Total Volume. If the correlation coefficient is positive and close to 1, it would indicate that as the Total Volume increases, the Average Price also tends to increase. On the other hand, if the correlation coefficient is negative and close to -1, it would indicate that as the Total Volume increases, the Average Price tends to decrease. A correlation coefficient close to 0 would indicate that there is no correlation between the two variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56c15c-378f-4db7-b758-b0dd446a0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Set up the figure and plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title('Correlation Matrix of Avocado Dataset')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c66726-0d12-4b2a-bdd8-ba846b3a07c6",
   "metadata": {},
   "source": [
    "In this code, we first load the avocado dataset and then calculate the correlation matrix using the corr() method in pandas. Then, we use the seaborn library's heatmap() function to plot the correlation matrix. We also add annotations to the cells to show the exact correlation coefficients. Finally, we add a title to the plot using matplotlib and display the plot using plt.show().\n",
    "\n",
    "The resulting plot will show the correlation between all pairs of variables in the avocado dataset. The cells that are shaded in red indicate positive correlation, while those shaded in blue indicate negative correlation. The darker the color, the stronger the correlation.\n",
    "\n",
    "In this code, we set the figsize parameter in plt.subplots() to a tuple of (10, 8), which will create a plot with a width of 10 inches and a height of 8 inches. You can adjust these values to your desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60474f-5d46-4f47-b1de-949df40c88a5",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 11 - Regression analysis<a class=\"anchor\" id=\"AVO_page_11\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce4105-fd1a-4276-a150-349d732c9035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the regression model\n",
    "X = df[['Total Volume', 'type', 'region']]\n",
    "X = pd.get_dummies(X, columns=['type', 'region'], drop_first=True)\n",
    "y = df['AveragePrice']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model and print the results\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831fdeb-389d-41b7-8286-604f92fac46f",
   "metadata": {},
   "source": [
    "In this code, we first load the avocado dataset and then set up the regression model using the OLS function in statsmodels. We specify the independent variables as Total Volume, type, and region, and convert the categorical variables type and region into dummy variables using pd.get_dummies().\n",
    "\n",
    "Next, we fit the model using model.fit() and print the summary of the results using model.summary(). The summary includes information on the coefficients of each variable, the R-squared value, and other statistics.\n",
    "\n",
    "The resulting plot will show four subplots: the predicted values versus Total Volume, a plot of the residuals versus Total Volume, a plot of the partial regression plot of Average Price on Total Volume with the influence of the other independent variables removed, and a plot of the component plus residual plot. These plots can help to assess the assumptions of the regression model and identify any issues with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5756d-a38c-4a9d-8cdf-369149d61489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "sm.graphics.plot_regress_exog(model, 'Total Volume', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e439e0d-335e-4caf-8c2b-1ef7f52f4053",
   "metadata": {},
   "source": [
    "## Explained results\n",
    "\n",
    "The output shows the results of an Ordinary Least Squares (OLS) regression analysis. The dependent variable is the Average Price of avocados, and the independent variables include Total Volume, type, and region.\n",
    "\n",
    "The R-squared value of 0.548 indicates that approximately 54.8% of the variability in the dependent variable can be explained by the independent variables.\n",
    "\n",
    "The F-statistic of 400.4 and the associated p-value of 0.00 suggest that the regression model is statistically significant.\n",
    "\n",
    "The coefficients for each independent variable can be interpreted as follows:\n",
    "\n",
    "Total Volume: For a one-unit increase in Total Volume, the Average Price is expected to decrease by 1.231e-06 units, holding all other variables constant.\n",
    "\n",
    "Type: The 'organic' type of avocado is associated with a higher Average Price than the 'conventional' type.\n",
    "\n",
    "Region: The regression model includes a separate coefficient for each region, representing the average difference in Average Price compared to the reference region (Albany). For example, the coefficient for the region Atlanta is -0.03, indicating that the Average Price in Atlanta is 0.03 lower on average than in Albany, holding all other variables constant.\n",
    "\n",
    "Overall, the regression analysis suggests that Total Volume, type, and region are significant predictors of Average Price for avocados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458a66a-8eb0-4290-852e-c88621a96ab2",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 12 - T-tests<a class=\"anchor\" id=\"AVO_page_12\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d55be-f126-4274-b6e4-c6fdb127c21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfadfc-ef7d-404d-9254-a1559fa963c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform a t-test to determine if there is a significant difference in the Average Price of conventional avocados versus organic avocados:\n",
    "\n",
    "conventional = df[df['type'] == 'conventional']['AveragePrice']\n",
    "organic = df[df['type'] == 'organic']['AveragePrice']\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(conventional, organic)\n",
    "\n",
    "print('T-test result:')\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d384e5c-c5c6-4471-a60f-aab5d19f3027",
   "metadata": {},
   "source": [
    "The t-test result provides the t-statistic and the associated p-value. If the p-value is less than the significance level (usually 0.05), we can reject the null hypothesis and conclude that there is a significant difference between the means of the two groups.\n",
    "\n",
    "The t-test result shows that the t-statistic is -105.587 and the p-value is 0.0. This means that there is a significant difference in the Average Price of conventional avocados versus organic avocados. The negative t-statistic suggests that the average price of conventional avocados is lower than the average price of organic avocados. The p-value of 0.0 indicates that the probability of obtaining such a large difference in means by chance alone is extremely low, and we can reject the null hypothesis that there is no difference between the means of the two groups.\n",
    "\n",
    "Note that the example above assumes that the two groups have equal variances. If the variances are unequal, a Welch's t-test can be used instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661e460-bed2-4ae0-a3b4-5fc0e8810144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_stat, p_val = stats.ttest_ind(conventional, organic, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cda227-0a33-49e6-b86a-c4da66ee6643",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 13 - Chi-squared test<a class=\"anchor\" id=\"AVO_page_13\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5208dc4-900f-485d-8046-64aeb632ab5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create contingency table\n",
    "contingency_table = pd.crosstab(df['type'], df['region'])\n",
    "print(contingency_table)\n",
    "\n",
    "# conduct chi-squared test\n",
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "print(\"Chi-squared test statistic:\", chi2_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895fbb2-dad5-4415-946f-3eb38aaeca0c",
   "metadata": {},
   "source": [
    "## Explained Results\n",
    "\n",
    "The chi-squared test result indicates that there is no significant association between the type of avocado and the region where they are produced. The chi-squared test statistic is very low (0.026), which indicates that the observed frequency distribution is not significantly different from the expected frequency distribution. The p-value of 1.0 also supports this result, indicating that there is no evidence to reject the null hypothesis that there is no association between the type of avocado and the region where they are produced. Therefore, we can conclude that the type of avocado and the region where they are produced are independent categorical variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a961c8-c084-4aa8-8207-ff5e430d6e1b",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 14 - Time-series analysis<a class=\"anchor\" id=\"AVO_page_14\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e132e0a-f025-4cd5-b223-ae7bf560f6a8",
   "metadata": {},
   "source": [
    "df.info()To perform time-series analysis, we first need to convert the 'Date' column to a pandas datetime object and set it as the index of the DataFrame. Then, we can use various time-series analysis techniques such as decomposition, forecasting, and autocorrelation to examine trends and patterns in the data over time.\n",
    "\n",
    "For example, to examine if there is a seasonal pattern in the sales of avocados, we can use seasonal decomposition. We can use the statsmodels library to perform seasonal decomposition and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e3194-571f-4de0-b23f-02fdc0a429cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752de502-fecd-4402-91fd-8b0cd62c930c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a deep copy of df and assign it to df2\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac74b3-556d-466a-8af9-f95d08c02e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Date column to datetime format and set it as the index\n",
    "df2['Date'] = pd.to_datetime(df['Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f20b55-dd5f-4f29-b607-81d89fff497c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9bc57-dda4-4114-bf23-aca61dd48101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code sets the 'Date' column as the index of the DataFrame named 'df2' and removes the 'Date' column. \n",
    "# This is done using the pandas function 'set_index' with the parameter 'inplace' set to True. \n",
    "# This will modify the DataFrame 'df2', making the 'Date' column irrelevant.\n",
    "df2.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced67957-596f-4248-bc0a-2f27a6c96d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# notice that the Date column has vanished\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb46502-07ea-4a3b-8c10-0e2c54da2f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the data by week and calculate the average price and total volume for each week\n",
    "weekly_data = df2.resample('W').agg({'AveragePrice': 'mean', 'Total Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d61c78-673b-4a8b-83d1-e311b37886f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the time series of Total Volume\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "weekly_data['Total Volume'].plot(ax=ax)\n",
    "ax.set(title='Total Avocado Sales by Week', xlabel='Date', ylabel='Total Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966eb0a-5464-4a82-a3e9-17707a7aaf6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decompose the time series to visualize any trends and seasonal patterns\n",
    "decomposition = sm.tsa.seasonal_decompose(weekly_data['Total Volume'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31148f-4101-4d6a-aa02-68a7f379cd54",
   "metadata": {},
   "source": [
    "This code loads the avocado dataset and converts the 'Date' column to datetime format, sets it as the index, and groups the data by week. It calculates the average price and total volume for each week and then plots the time series of the total volume. The code then decomposes the time series using the seasonal decomposition function from the statsmodels library to visualize any trends and seasonal patterns. The resulting plot shows the original time series, the trend component, the seasonal component, and the residual component.\n",
    "\n",
    "In time series analysis, a time series can be decomposed into several components: trend, seasonal, and residual.\n",
    "\n",
    "The trend component represents the long-term changes in the time series. It is the underlying pattern or direction in which the series is moving over time, regardless of short-term fluctuations. The trend component can be linear, non-linear, or a combination of both.\n",
    "\n",
    "The seasonal component represents the periodic fluctuations that occur within the time series at fixed intervals, such as daily, weekly, monthly, or yearly. Seasonality is often observed in economic, environmental, and social data, and it can be caused by various factors such as weather, holidays, and cultural events.\n",
    "\n",
    "The residual component, also known as the error or noise component, represents the random variation in the time series that cannot be explained by the trend or seasonal components. It includes all other factors that affect the series but are not accounted for by the model.\n",
    "\n",
    "To summarize, the original time series is the complete set of data over time, including all the components mentioned above. The trend component represents the long-term pattern of change, the seasonal component represents the periodic fluctuations, and the residual component represents the unexplained variation or noise in the series.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The seasonal decomposition plot can help us identify any recurring patterns in the data, such as weekly or monthly seasonal patterns, which can inform forecasting models and help us make predictions about future sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef2617-5d80-4d4d-a50b-bb94c1bace65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decompose the time series to visualize any trends and seasonal patterns\n",
    "decomposition = sm.tsa.seasonal_decompose(weekly_data['Total Volume'], model='additive')\n",
    "\n",
    "# Create a 2x2 grid of subplots\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot the original time series\n",
    "axs[0].plot(weekly_data['Total Volume'])\n",
    "axs[0].set_title('Original Time Series')\n",
    "\n",
    "# Plot the trend component\n",
    "axs[1].plot(decomposition.trend)\n",
    "axs[1].set_title('Trend Component')\n",
    "\n",
    "# Plot the seasonal component\n",
    "axs[2].plot(decomposition.seasonal)\n",
    "axs[2].set_title('Seasonal Component')\n",
    "\n",
    "# Plot the residual component\n",
    "axs[3].plot(decomposition.resid)\n",
    "axs[3].set_title('Residual Component')\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead8520-3298-4872-8246-6d36c448b3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decompose the time series to visualize any trends and seasonal patterns\n",
    "decomposition = sm.tsa.seasonal_decompose(weekly_data['Total Volume'], model='additive')\n",
    "\n",
    "# Create a new figure\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original time series\n",
    "plt.plot(weekly_data['Total Volume'], color='black', label='Original Time Series')\n",
    "\n",
    "# Plot the trend component\n",
    "plt.plot(decomposition.trend, color='red', label='Trend Component')\n",
    "\n",
    "# Plot the seasonal component\n",
    "plt.plot(decomposition.seasonal, color='green', label='Seasonal Component')\n",
    "\n",
    "# Plot the residual component\n",
    "plt.plot(decomposition.resid, color='blue', label='Residual Component')\n",
    "\n",
    "# Set the x and y-axis labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Volume')\n",
    "plt.title('Time Series Decomposition')\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d297792-8b19-412d-bd92-8de7a2bd82d2",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 15 - Summary<a class=\"anchor\" id=\"AVO_page_15\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386e2cd-41b5-4bee-aa8d-73bb6d467cfe",
   "metadata": {},
   "source": [
    "Write summary here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dbe3b-0733-400d-8ad6-a51c09e96f58",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">\n",
    "\n",
    "# Page 16 - Future Work<a class=\"anchor\" id=\"AVO_page_16\"></a>\n",
    "\n",
    "[Back to Top](#AVO_toc)\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:MediumAquamarine;background-color:MediumAquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4b1d9-d4eb-4add-ac8c-c1d6c2c47360",
   "metadata": {},
   "source": [
    "write Future ideas and work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c69c6-2238-4d21-beae-684e5008e970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
